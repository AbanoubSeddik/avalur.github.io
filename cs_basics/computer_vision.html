<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="apple-mobile-web-app-capable" content="yes" />
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

		<title>Computer vision intro</title>

		<link rel="stylesheet" href="../dist/reset.css">
		<link rel="stylesheet" href="../dist/reveal.css">
		<link rel="stylesheet" href="../dist/theme/black.css">

        <!-- Theme used for syntax highlighted code -->
		<link rel="stylesheet" href="../plugin/highlight/monokai.css">
		<style>
			.column {
			  float: left;
			  width: 48%;
			  padding: 2px;
			}
			/* Clear floats after image containers */
			.row::after {
			  content: "";
			  clear: both;
			  display: table;
			}
		</style>
</head>
	<body onload="totalWrapper();">
		<div class="reveal">
			<div class="slides">
				<section>
					<div>
						<img src="images/nup_logo_dark.jpeg" alt="nup_logo" />
					</div>
					<h2>CS Basics with Python</h2>
					<h3>Computer vision intro</h3>
					<br />
					Alex Avdiushenko <br />
					November 29, 2023
				</section>
				<section>
					<section>
						<h2>What is computer vision?</h2>
						<div>
							<img src="images/cv_search.png" alt="cv_search" />
						</div>
					</section>
					<section>
						<h2>What is vision?</h2>
						<ul>
							<li>Eyes are the human organ that provides 80 percent of information about
								the surrounding world to a person. (Though, it depends on how you calculate it)</li>
							<li>Vision is the extraction of information from the visual signal hitting the retina</li>
						</ul>
						<div>
							<img src="images/Illustration_of_a_detailed_human_eye_anatomy.png" alt="vision" width="40%"/>
						</div>
					</section>
					<section>
						<h2>Computer vision</h2>
						<ul>
							<li>The same concept, only instead of the brain it's a computer,
								and instead of an eye it's a camera</li>
						</ul>
						<div>
							<img src="images/cv_illustration.png" alt="cv_illustration" width="40%"/>
						</div>
					</section>
					<section>
						<h2>General Challenge in Computer Vision</h2>
                        <div class="fragment" style="margin-bottom:20px;">
                            <div class="typesetting">
							<p>To learn how to respond to the same questions that a person can answer by looking at a photo or video.
								This is a kind of Turing test for a computer vision system.</p>
							</div>
						</div>
					</section>
					<section>
						<h2 style="text-align: left">Our Dreams</h2>
                        <div class="fragment" style="margin-bottom:20px;">
                            <div class="typesetting">
								<div class="row">
								  <div class="column">
									<img src="images/cv_today.png" alt="cv_today" />
								  </div>
								  <div class="column">
									<ul>
										<li>For the computer to "understand" the semantics of the scene in the image</li>
										<li>To automatically recognize what and where is depicted</li>
										<li>To categorize and identify objects, determine their properties and relationships</li>
									</ul>
								  </div>
								</div>
							</div>
						</div>
					</section>
					<section>
						<h2>Existing Obstacles: Object</h2>
						<img src="images/obstacles.png" alt="obstacles" width="80%"/>
					</section>
					<section>
						<h2>How We See an Object</h2>
						<img src="images/lamps.png" alt="lamps" width="80%"/>
					</section>
					<section>
						<h2>Semantic gap: from low-level features to the objects</h2>
						<img src="images/low_to_high.png" alt="low_to_high" width="70%"/>
					</section>
				</section>
				<section>
					<section>
						<h2>A few facts about our visual perception:</h2>
							<div class="fragment" style="margin-bottom:20px;">
								<div class="typesetting">
								<ol>
									<li>Our brain often "completes" the picture and adds semantics (We can all recognize "something" or "someone" in the outline of a cloud)</li>
									<li>The visual system is self-learning
										<ul>
										   <li>It's difficult for Europeans to distinguish Asian faces, and vice versa</li>
										   <li>We look for familiar patterns in images</li>
										   <li>Always we are trying to predict (with strong internal prior) the whole picture</li>
										</ul>
									</li>
								</ol>
								</div>
							</div>
					</section>
					<section>
						<img src="images/optical-b1.gif" alt="optical" width="50%"/>
					</section>
					<section>
						<img src="images/optical-b-explained.gif" alt="optical-b-explained" width="100%"/>
					</section>
					<section>
						<h2>Brightness Adaptation and Contrast Sensitivity</h2>
						<p>The visual system can adapt to a brightness range of
							around $10^{10}$. The subjective brightness
							is a logarithmic function of the physical brightness.</p>
					</section>
					<section>
						<h2 style="text-align: left">Photopic and Scotopic vision</h2>
							<div class="fragment" style="margin-bottom:20px;">
								<div class="typesetting">
								Are two different types of vision that humans possess,
								and they function under different light conditions.
								<ul>
									<li>Photopic Vision: This type of vision dominates in well-lit conditions,
										such as in daylight or under bright artificial lighting.
										It involves the use of <span style="color: orange">cones</span>,
										the photoreceptor cells responsible for color perception.
										It permits color and high acuity vision to see fine details.</li>
									<li>Scotopic vision takes over in low light or night-time conditions.
										It involves the use of <span style="color: orange">rods</span>,
										that are much more sensitive to light than cones but do not provide
										color information and doesn't allow for the resolution of fine details.</li>
								</ul>
								</div>
							</div>
					</section>
				</section>
				<section>
					<section>
						<h2 style="text-align: left">Whirlwind, MIT 1951</h2>
                        <div class="fragment" style="margin-bottom:20px;">
                            <div class="typesetting">
								<div class="row">
								  <div class="column">
									<ul>
										<li>The first computer to display text and graphics in real time on a monitor</li>
										<li>Displayed the map with dots, the airplane with an icon</li>
										<li>Used a "light pen" for interaction with the screen (requesting information about an object)</li>
									</ul>
								  </div>
								  <div class="column">
									<img src="images/mit_1951.png" alt="mit_1951" width="70%" />
								  </div>
								</div>
							</div>
						</div>
					</section>
					<section>
						<h2 style="text-align: left">The Birth of Computer Vision (1960)</h2>
						<p>Determining the mutual arrangement of simple geometric figures</p>
						<a href="https://www.di.ens.fr/willow/teaching/recvis09/slides/lecture1.pdf">
							<img src="images/cv_origin.png" alt="cv_origin" width="60%" />
						</a>
					</section>
					<section>
						<h2>Viola-Jones face detector, 2001</h2>
						<img src="images/lena.png" alt="lena" width="50%" />
					</section>
					<section>
						<h2>Deep learning, 2010+</h2>
						<img src="images/dogsplayingpoker_3370414k.jpg" alt="dogsplayingpoker" width="70%" />
					</section>
				</section>
				<section>
					<section>
						<h2>What is color?</h2>

					</section>
				</section>
			</div>
		</div>

		<script src="../dist/reveal.js"></script>
		<script src="../plugin/notes/notes.js"></script>
		<script src="../plugin/markdown/markdown.js"></script>
		<script src="../plugin/highlight/highlight.js"></script>
		<script src="../plugin/math/math.js"></script>
		<script src="../scripts/utils.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({
				hash: true,
				// The "normal" size of the presentation, aspect ratio will
				// be preserved when the presentation is scaled to fit different
				// resolutions. Can be specified using percentage units.
				width: '100%',
				height: '100%',
				// Factor of the display size that should remain empty around the content
				margin: 0.08,

				// Bounds for smallest/largest possible scale to apply to content
				minScale: 0.2,
				maxScale: 2.0,
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes, RevealMath.KaTeX ]
			});

			Reveal.addEventListener('fragmentshown', function (event) {
				if (lettersAnimate) {
					[...event.fragment.getElementsByClassName('typesetting')].forEach(element => {
						playAnimation(element);
					});
				}
			});

		</script>
    </body>
</html>
