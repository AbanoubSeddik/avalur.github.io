<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="apple-mobile-web-app-capable" content="yes" />
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

        <meta name="description" content="From AlphaZero to AlphaGeometry">
        <meta name="author" content="Alex Avdiushenko" />
        <meta name="keywords" content="AlphaZero, AlphaGeometry">

		<title>From AlphaZero to AlphaGeometry</title>

		<link rel="stylesheet" href="../dist/reset.css">
		<link rel="stylesheet" href="../dist/reveal.css">
		<link rel="stylesheet" href="../dist/theme/league.css">
		<link rel="stylesheet" href="./css/style.css">

	    <link href="../css/font-awesome/css/all.min.css?ver=1.2.0" rel="stylesheet">

        <!-- Theme used for syntax highlighted code -->
		<link rel="stylesheet" href="../plugin/highlight/monokai.css">

		<!-- Include Chart.js CDN -->
		<script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
		<script src="../plugin/reveald3.js"></script>
	</head>
	<body onload="totalWrapper();">
		<div class="reveal">
			<div class="slides">
                <section id="title">
					<br><br><br>
						<h2>From AlphaZero to AlphaGeometry</h2>
					<div class="column">
						<a href="https://youtu.be/qhbuKbxJsk8?si=jG10edUWsVoWZWlT">
							<div class="fig-container no-margin-top" data-file="images/modular-multiplication.html"
							style="padding-left: 10%"></div>
						</a>
					</div>
					<div class="column">
						<br/><br/><i>by</i><br/>
						<p>Alex Avdiushenko</p>
							<a href="mailto:aleksandr.avdiushenko@jetbrains.com">aleksandr.avdiushenko@jetbrains.com</a>
					</div>
                </section>
				<section>
					<h3>Brief history of computer programs, playing Chess and Go</h3>
					<ul>
						<li class="fragment">1960-s: Beginnings: the very first attempts</li>
						<li class="fragment">1990-s: still far from matching the skills of human players</li>
						<li class="fragment">1997: world chess champion Garry Kasparov was defeated by Deep Blue</li>
						<li class="fragment">1997: but in Go Janice Kim (1p) won HandTalk program with a 25-stone handicap</li>
						<li class="fragment">2010: on European Go Congress MogoTW program won 19x19 Go against
							Catalin Taranu (5p out of 9p)</li>
					</ul>
					<br><br>
					<p class="fragment r-frame">
						What is the problem? Why is Go harder than Chess for computer?
					</p>
				</section>
				<section>
					<h3 style="text-align: left">Schematic tree of possible moves in Go</h3>
						<img src="images/moves_tree_in_go.png" width="1400" style="border-radius: 5%">

					<aside class="notes">
						Unlike Chess, for example, the tree of possible moves in Go expands greatly —
						with over 200 variants for each next move.

						Due to this, up until 2015, the best Go-playing programs could only reach an amateur level.
						Some developers claimed that computers would never be able to beat the best human players.
						However, most AI specialists believed that such a program would be developed,
						but not before 2020–2025.
					</aside>
				</section>
				<section>
					<h3>Why is Go really hard for computer?</h3>

					<ul>
						<li>Huge branching factor</li>
						<ul class="fragment">
							<li>Chess: there are 30–40 possibilities, and lots of them are obviously weak</li>
							<li>Go: there are about 250 possibilities, and about 100 from them are "reasonable"</li>
						</ul>
						<li>Hard to evaluate current position</li>
						<ul class="fragment">
							<li>Chess: one can count pieces material and there are simple heuristics</li>
							<li>Go: it is really challenging even to understand who wins in the final position</li>
						</ul>
					</ul>

					<aside class="notes">
						There are at least two reasons why Go is hard, one is quantative, the other is qualitative.

						Go has a much larger branching factor than Chess.

						The qualitative reason is that it is way more challenging to evaluate the current position in Go.
						Computers could not understand who is winning in Go. There was even a whole benchmark of
						different final positions in Go, according to human evaluation. And the task was simply
						to determine, who won.
					</aside>
				</section>
				<section data-background-color="antiquewhite">
					<h3 style="text-align: left">2000-s: Monto-Carlo Tree Search</h3>
					<div class="fragment">
						<div class="typesetting">
							<ul>
								<li>In the 2000s, Monte Carlo Tree Search (MCTS) algorithms were introduced,
								resulting in significant improvements in the performance of Go programs</li>
								<li>We launch <em>random simulations</em> from the current position,
									observe which branches yield more wins, and then repeat the process</li>
							</ul>

							<img src="images/MCTS_svg.png" style="border-radius: 5%">
						</div>
					</div>
				</section>
				<section>
					<h3 style="text-align: left">Monte Carlo Tree Search — UCB1</h3>
					<div class="fragment">
						<div class="typesetting">
							<p style="text-align: left">The main part of MCTS is the formula for selection of the next node.
							The UCB1 formula looks like this (the same as in multi-armed bandits):</p>

							$$ UCB_1 = \frac{w_i}{n_i} + c \sqrt{\frac{\ln t}{n_i}} $$
							<p style="text-align: left">where:</p>
							<ul>
								<li>$w_i$ is the number of wins</li>
								<li>$n_i$ is the count of simulations for the node associated with action $i$</li>
								<li>$c$ is the parameter, by default $c=\sqrt{2}$</li>
								<li>$t = \sum\limits_i n_i$ is the total count of simulations for the parent node</li>
							</ul>

							<p style="text-align: left">
								The algorithm prefers actions with higher estimated rewards and higher uncertainties.
							</p>
						</div>
					</div>
				</section>
				<section data-background-image="images/lee_sedol.png">
					<div class="fragment">
						<div class="typesetting">
							<h3 style="text-align: left"><p>AlphaGo vs. Lee Sedol</p>
							9-15 March 2016</h3>
						</div>
					</div>
					<div class="fragment">
						<div class="typesetting">
							<p style="text-align: left;font-size: 52px"> Forecast was 1 : 4 </p>
						</div>
					</div>
					<div class="fragment">
						<div class="typesetting">
							<p style="text-align: left;font-size: 52px"> Result was 4 : 1 </p>
						</div>
					</div>
					<br><br><br><br><br><br><br><br><br><br><br><br>
					<aside class="notes">
						And then, March 2016 became.
						This is a photo from a Go match in which the legendary Korean player Lee Sedol,
						one of the best in the world, is playing against an AI-based program, AlphaGo.

						Before the match, Lee Sedol, in fact being a very modest person,
						said that he would either win cleanly 5:0,
						or he might underestimate the strength of the program and somewhere due to a mistake,
						he would win 4:1.

						What do you think the result was? The computer won with a score of 4:1.
						It was so-called "sputnik"-moment for all Asia, when they truly understood that
						deep learning is huge thing.
					</aside>
				</section>
				<section>
					<h3>What is inside AlphaGo?</h3>

					<div class="fragment">
						<div class="typesetting">
							<ol>
								<li>
									Supervised learning (SL) policy network for next move prediction:
									<ul>
										<li>13-layers CNN for features extraction from the board</li>
										<li>30 billion positions from human expert games</li>
										<li>Moves probability distribution as output: $p_\sigma(a \mid s)$</li>
										<li>Accuracy reaches 57%, which is very high</li>
										<li>Also train fast and worse strategy $p_\pi$ (accuracy is 24%,
											but inference time is much less: 3 millisecond $\to$ 2 nanosecond)</li>
									</ul>
								</li>
							</ol>
						</div>
					</div>

					<aside class="notes">
					</aside>
				</section>
				<section>
					<h3>AlphaZero</h3>

					<p style="text-align: left">AlphaZero is a more generalized and simple variant
						of the AlphaGo algorithm, and is capable of playing Chess, Shogi and Go.</p>

						<div class="fragment">
							<div class="typesetting">
							<ul>
								<li>AlphaZero is a reinforcement learning system,
									it learns to play by playing games against itself
									and improving from its mistakes only</li>
								<li>Silver et al., 2017: <a href="https://arxiv.org/abs/1712.01815">
									"Mastering Chess and Shogi by Self-Play with
									a General Reinforcement Learning Algorithm"</a></li>
								<li>AlphaZero also outperformed Stockfish, one of the top-ranked chess engines,
									winning 28 games and drawing the rest in a 100-game match</li>
							</ul>
							<img src="images/AlphaZeroPlots.png" style="border-radius: 5%">
							</div>
						</div>
				</section>
				<section>
					<h3 style="text-align: left">Inside AlphaZero</h3>
						<div class="fragment">
							<div class="typesetting">
								<ul>
									<li>we have a deep neural network for next move prediction and position evaluation</li>
									<li>it self-plays and simultaneously builds an MCTS tree</li>
									<li>it improves both the NN weights (via RL) and MCTS tree</li>
								</ul>

								<img src="images/AlphaGoZero.png" style="border-radius: 3%;width: 50%">
							</div>
						</div>
				</section>
				<section>
					<p style="text-align: left">We minimize</p>
					$$ Loss = (z-v)^2 - \pi^T \log p + c \|\theta\|^2 $$
					<p style="text-align: left">
						where $p$ is probabilities from NN, $\pi$ — improved by MCTS probabilities
					</p>
				</section>
				<section data-background-image="images/JBA_AlphaZero_course.png">
				</section>
				<section>
					<h3>And what about State-of-the-art?</h3>
						<ol>
							<div class="fragment">
								<li class="typesetting">
								  <a href="https://deepmind.google/discover/blog/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models/">
									  FunSearch, 14 Dec 2023:</a>
								  Making new discoveries in mathematical sciences using Large Language Models</li>
							</div>
						</ol>
					<div class="fragment">
						<div class="typesetting">
							<p style="text-align: left">By searching for “functions” written in Python,
							FunSearch made the first discoveries in open problems in mathematical sciences using LLMs.</p>
							<ul>
								<li>They first address the <a href="https://en.wikipedia.org/wiki/Cap_set">cap set problem</a>,
								an open challenge, which has vexed mathematicians in multiple research areas for decades</li>
								<li>The “bin packing” problem looks at how to pack items
									of different sizes into the smallest number of bins</li>
							</ul>
						</div>
					</div>
				</section>
				<section data-background-color="white">
					<img src="images/cap_set_specs.png" alt="cap_set_specs" width="90%">
				</section>
				<section data-background-color="white">
					<img src="images/cap_set_results.png" alt="cap_set_results" width="90%">
				</section>
				<section>
					<h3>The “bin packing” problem</h3>
					<br>
					<video width="90%" controls>
						<source src="images/binpack_animation_v3_DcLQBh5.mp4" type="video/mp4">
						Your browser does not support the video tag.
					</video>
				</section>
				<section>
					<div class="fragment">
						<div class="typesetting">
							<ul>
								<li><span style="color: orange">FunSearch</span> produces programs generating the solution</li>
								<li>They use <span style="color: orange">Codey</span>, an LLM built on top of
									the <span style="color: orange">PaLM2</span> model,
									which has been fine-tuned on a large corpus of code
									and is publicly accessible through its API.
									It is interesting, that without any fine-tuning on math problems.</li>
								<li>They have chosen to work with a fast-inference model
									(rather than slower-inference, higher-quality)</li>
								<li>LLM + evolutionary algorithm + search in the space of programs</li>
								<li><span style="color: orange">FunSearch</span> suggests a solution,
									which is examined by researchers, who may note features of interest.
									These features are used to refine the search,
									leading to better solutions. This process can be iterated,
									with both humans and search consistently in the loop</li>

							</ul>
						</div>
					</div>
				</section>
				<section>
					<ol start="2">
						<li class="typesetting">
						<a href="https://www.nature.com/articles/s41586-023-06747-5">AlphaGeometry, 17 Jan 2024:</a>
						An Olympiad-level AI system for [school tasks] geometry</li>
					</ol>
					<br><br>
					<div class="typesetting">
						<ul style="text-align: left">
							<li class="fragment">Solves 25 out of 30 latest IMO geometry problems</li>
							<li class="fragment">The previous best method only solves 10 problems</li>
							<li class="fragment">By using existing symbolic engines on a diverse set of random theorem premises,
								they extracted 100 million synthetic theorems and their proofs,
								many with more than 200 proof steps,
								four times longer than the average proof length of olympiad theorems</li>
							<li class="fragment">Then produced nearly 10 million synthetic proof steps that construct auxiliary points,
								reaching beyond the scope of pure symbolic deduction</li>
						</ul>
					</div>
				</section>
				<section data-background-color="white">
					<img src="images/AlphaGeomFig1.png" alt="AlphaGeomFig1" width="90%">
				</section>
				<section>
					<ul>
						<li>Tokens are $(P, N, G(N))$ = (premises, conclusion, proof)</li>
						<li>A transformer language model effectively learns to generate the proof,
							conditioning on theorem premises and conclusion</li>
						<li>Inference: on a high level, proof search is a loop in which
							the LLM and the symbolic deduction engine take turns to run</li>
					</ul>
				</section>
				<section data-background-color="white">
					<img src="images/proof_lengths.png" alt="proof_lengths" width="90%">
				</section>
				<section data-background-color="white">
					<img src="images/AlphaGeometryRes.png" alt="AlphaGeometryRes" width="70%">
				</section>
				<section data-background-color="white">
					<img src="images/AG_diff_domains.jpg" alt="AG_diff_domains" width="70%">
				</section>
				<section>
					<h3>Instead of a conclusion</h3>
					<div class="fragment">
						<div class="typesetting">
						<p style="text-align: left">AlphaGeometry paper shows that language models can learn to come up with
							auxiliary constructions from synthetic data, in which problem statements
							and auxiliary constructions are randomly generated together
							and then separated using the traceback algorithm to identify the dependency difference.
							Concretely, the AlphaGeometry framework requires the following ingredients:</p>
							<ol>
								<li>An implementation of the domain’s objects and definitions</li>
								<li>A random premise sampler</li>
								<li>The symbolic engine(s) that operate within the implementation (1)</li>
								<li>A traceback procedure for the symbolic engine</li>
							</ol>
						<p style="text-align: left">Using these four ingredients and the algorithm described in the main text,
							one can generate synthetic data for any target domain.</p>
						</div>
					</div>
				</section>
            </div>
        </div>
		<script src="../dist/reveal.js"></script>
		<script src="../plugin/notes/notes.js"></script>
		<script src="../plugin/markdown/markdown.js"></script>
		<script src="../plugin/highlight/highlight.js"></script>
		<script src="../plugin/math/math.js"></script>
		<script src="../scripts/utils.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({
				hash: true,
				// The "normal" size of the presentation, aspect ratio will
				// be preserved when the presentation is scaled to fit different
				// resolutions. Can be specified using percentage units.
				width: '100%',
				height: '100%',
				// Factor of the display size that should remain empty around the content
				margin: 0.08,

				slideNumber: true,
				showSlideNumber: 'speaker',
				hashOneBasedIndex: true,
				autoPlayMedia: true,
				// showNotes: 'separate-page',

  			    // Activate the scroll view
  				// view: 'scroll',
  				// Force the scrollbar to remain visible
  				// scrollProgress: true,

				// Bounds for smallest/largest possible scale to apply to content
				minScale: 0.2,
				maxScale: 2.0,
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes, RevealMath.KaTeX, Reveald3 ]
			});

			Reveal.addEventListener('fragmentshown', function (event) {
				if (lettersAnimate) {
					[...event.fragment.getElementsByClassName('typesetting')].forEach(element => {
						playAnimation(element);
					});
				}
			});

		  // Data for Pie Chart
		  const data = {
			labels: [
			  '44% Yes, all the time',
			  '25% Yes, once a week',
			  '19% Not often',
			  '12% No'
			],
			datasets: [{
			  label: 'Survey Results',
			  data: [43.8, 25, 18.8, 12.5],
			  backgroundColor: [
				'green',
				'lightgreen',
				'red',
				'darkred',
			  ],
			  hoverOffset: 4
			}]
		  };

		  // Configuration for Chart.js
		  const config = {
			type: 'pie',
			data: data,
			options: {
			  responsive: true,
			  plugins: {
				legend: {
				  position: 'top',
					labels: {
					  font: {
						  size: 32
					  }
					}

				}
			  }
			},
		  };

		  // Initialize Chart.js Pie Chart
		  const survey_results = new Chart(
			document.getElementById('survey_results'),
			config
		  );
        </script>
    </body>
</html>